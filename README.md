# Faster Whisper GUI

A professional Gradio-based GUI for faster-whisper audio/video transcription with CUDA acceleration and multiprocessing architecture.

## Features

- âœ… **CUDA Acceleration** - GPU-accelerated transcription (with CPU fallback)
- âœ… **Multiprocessing Architecture** - Solves Gradio threading conflicts with CUDA
- âœ… **Video Support** - Automatic video-to-audio conversion using FFmpeg
- âœ… **Multiple Formats** - Export to TXT, JSON, SRT, and VTT subtitle formats
- âœ… **Batch Processing** - Process multiple files with batched inference
- âœ… **Smart Organization** - Automatic file organization with subfolders
- âœ… **Real-time Progress** - Live progress tracking and detailed logs
- âœ… **SOLID Architecture** - Clean, modular, and maintainable code

## Requirements

- Python 3.12+
- FFmpeg (required for video conversion)
- CUDA-capable GPU (optional, for acceleration)

## Installation

1. **Install dependencies:**

```bash
uv sync
```

Or with pip:

```bash
pip install -r requirements.txt
```

2. **Install FFmpeg:**

- **Windows**: Download from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH
- **Linux**: `sudo apt install ffmpeg`
- **macOS**: `brew install ffmpeg`

3. **For CUDA support (optional):**

Install CUDA drivers and libraries as per [faster-whisper documentation](https://github.com/SYSTRAN/faster-whisper#gpu)

## Usage

### Launch the GUI

```bash
python main.py
```

Or with uv:

```bash
uv run main.py
```

The GUI will be available at `http://localhost:7860`

### Default Configuration

The GUI comes with optimized default settings:

- **Model**: large-v3 (best accuracy)
- **Device**: CUDA (GPU acceleration)
- **Compute Type**: int8_float16 (balanced speed/accuracy)
- **Beam Size**: 5 (optimal quality)
- **Batch Size**: 8 (efficient processing)
- **VAD Filter**: Enabled (removes silence)
- **Word Timestamps**: Disabled (faster)
- **Batched Inference**: Enabled (faster for long files)
- **Output Formats**: TXT, JSON, SRT, VTT

### Workflow

1. **Upload Files** - Select audio/video files from `input/` folder
2. **Configure Settings** (optional - defaults are optimized):
   - Model: tiny, base, small, medium, large-v3, turbo
   - Device: CUDA or CPU
   - Language: Auto-detect or specify
   - Advanced options: beam size, batch size, VAD filter
3. **Start Transcription** - Click "ğŸš€ Start Transcription"
4. **View Results** - See transcripts in real-time in multiple formats
5. **Download** - Files are organized in `output/` folder with subfolders

### File Organization

```
output/
â”œâ”€â”€ video_name_YYYYMMDD_HHMMSS/
â”‚   â”œâ”€â”€ transcript.txt
â”‚   â”œâ”€â”€ transcript.json
â”‚   â”œâ”€â”€ transcript.srt
â”‚   â”œâ”€â”€ transcript.vtt
â”‚   â””â”€â”€ video_name.mp4  (moved after processing)
```

## Architecture

### Multiprocessing Design

The application uses a **multiprocessing architecture** to solve critical CUDA threading conflicts with Gradio:

**Problem**: Gradio's threading model conflicts with CUDA context initialization, causing `transcribe()` calls to hang indefinitely.

**Solution**: Transcription runs in a **separate process** with isolated CUDA context:

```
Main Process (GUI)              Worker Process
â”œâ”€â”€ File upload                 â”œâ”€â”€ CUDA initialization
â”œâ”€â”€ Video conversion            â”œâ”€â”€ Model loading
â”œâ”€â”€ Progress monitoring    â†â”€â”€â†’ â”œâ”€â”€ Transcription
â”œâ”€â”€ Result display              â””â”€â”€ Return segments
â””â”€â”€ Temp file cleanup
```

### SOLID Principles

Following clean architecture with single responsibility:

```
src/
â”œâ”€â”€ environment_checker.py   # Environment validation
â”œâ”€â”€ media_converter.py        # FFmpeg video-to-audio (main process)
â”œâ”€â”€ transcription_service.py  # Whisper model wrapper (worker process)
â”œâ”€â”€ file_manager.py           # File operations & organization
â”œâ”€â”€ output_formatter.py       # TXT/JSON/SRT/VTT generation
â”œâ”€â”€ config.py                 # Configuration & settings
â””â”€â”€ gui.py                    # Gradio interface + multiprocessing
```

**Key Design Decisions**:

- Video conversion happens in **main process** (UI responsibility)
- Transcription happens in **worker process** (isolated CUDA context)
- Clean separation via Queue-based IPC

## Technical Details

Default settings (can be modified in `src/config.py`):

- **Device**: CUDA (falls back to CPU if unavailable)
- **Compute Type**: float16 (CUDA) / int8 (CPU)
- **Model**: large-v3
- **Beam Size**: 5
- **VAD Filter**: Enabled
- **Audio Format**: WAV (16kHz, mono)

## Environment Validation

The application performs pre-flight checks:

1. âœ… FFmpeg availability (required)
2. âœ… CUDA availability (recommended)
3. âœ… Python dependencies
4. âœ… Device selection validation

If FFmpeg is missing, the application will exit with installation instructions.
If CUDA is selected but unavailable, transcription will be blocked.

## Supported Formats

**Audio**: MP3, WAV, M4A, FLAC, AAC, OGG, OPUS, WMA

**Video**: MP4, MKV, AVI, MOV, WMV, FLV, WEBM, M4V, MPG, MPEG

## Troubleshooting

### FFmpeg not found

```
Error: FFmpeg not found in PATH
Solution: Install FFmpeg and ensure it's in your system PATH
```

### CUDA not available

```
Warning: CUDA not available
Solution: Install CUDA drivers or use CPU mode
```

### Model download issues

```
Error: Cannot download model
Solution: Check internet connection, models are downloaded on first use
```

## License

This project uses [faster-whisper](https://github.com/SYSTRAN/faster-whisper) under the MIT License.

## Credits

- **faster-whisper** by SYSTRAN
- **Whisper** by OpenAI
- **Gradio** for the web interface
- **FFmpeg** for media conversion
